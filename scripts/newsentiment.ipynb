{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9b96ce-dbaa-44f5-b214-0a68142b1c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUses NewsMTSC to get pos, neg, neutral sentiment towards any entity. \\nCurrent pipeline is to read from NER, link to full body\\nand targetting entities containing certain substrings\\nRight now runs on \"alibaba\" containing entities but nothing else \\nand no coref resolution. \\n\\nruns on newsentiment environ NOT thesis.\\nAlso see pocs/newsentiment_poc.py\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uses NewsMTSC to get pos, neg, neutral sentiment towards any entity. \n",
    "Current pipeline is to read from NER, link to full body\n",
    "and targetting entities containing certain substrings\n",
    "Right now runs on \"alibaba\" containing entities but nothing else \n",
    "and no coref resolution. \n",
    "\n",
    "runs on newsentiment environ NOT thesis.\n",
    "Also see pocs/newsentiment_poc.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65962ed-c5fd-4f7e-af25-f6d1ac220bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from NewsSentiment import TargetSentimentClassifier\n",
    "from NewsSentiment.customexceptions import TooLongTextException, TargetNotFoundException\n",
    "from thesisutils import utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging, logging.config\n",
    "from pathlib import Path\n",
    "import logconfig\n",
    "\n",
    "lgconf = logconfig.logconfig(\"newssent\")\n",
    "logging.config.dictConfig(lgconf.config_dct)\n",
    "logger = logging.getLogger(__name__)\n",
    "# %%\n",
    "tsc = TargetSentimentClassifier()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5144d02-1a4f-44fb-87fa-dc2d08538415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x7f0390880c80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f37ec9bf-3ff1-451e-85f4-65f9938eeacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "# FUNCTIONS ###########################################\n",
    "def span_clean(span):\n",
    "    \"\"\"\n",
    "    span is a spacy span e.g. doc[1:14];\n",
    "    default is to return span.text,\n",
    "    but if we see a \"Post\" reference,\n",
    "    remove that clause before text conversion.\n",
    "    \"\"\"\n",
    "    delimiters = [\",\", \"(\", \"-\", \")\"]\n",
    "    delim_idx = []\n",
    "    for tok in span:\n",
    "        if tok.text in delimiters:\n",
    "            delim_idx.append(tok.i - span.start)\n",
    "    if delim_idx:\n",
    "        ls = []\n",
    "        subspan = span[: delim_idx[0]]\n",
    "        if not \"Post\" in subspan.text:\n",
    "            ls.append(subspan)\n",
    "        for i, el in enumerate(delim_idx):\n",
    "            if i + 1 == len(delim_idx):\n",
    "                subspan = span[el:]\n",
    "                if not \"Post\" in subspan.text:\n",
    "                    ls.append(subspan)\n",
    "            else:\n",
    "                subspan = span[el : delim_idx[i + 1]]\n",
    "                if \"Post\" in subspan.text:\n",
    "                    continue\n",
    "                ls.append(span[el : delim_idx[i + 1]])\n",
    "        return \"\".join(e.text for e in ls)\n",
    "    else:\n",
    "        if \"Post\" in span.text:\n",
    "            return \"\"\n",
    "        else:\n",
    "            return span.text\n",
    "\n",
    "\n",
    "# %%\n",
    "# NOTE: these functions take a standardized df;\n",
    "# STANDARDIZE IN FIRST LOADING STEP BEFORE passing to fns.\n",
    "def get_sentiment(row, doc, publication):\n",
    "    \"\"\"\n",
    "    returns dictionary with positive, negative, and neutral\n",
    "        probabilities for a given NER object.\n",
    "    Note: result has nan values when input is too long.\n",
    "    Be sure to do exploration / reporting later.\n",
    "    :param row: row of NER datafarme\n",
    "    :param doc: spacy nlped (w/ sentencizer) doc\n",
    "    \"\"\"\n",
    "    start = row.start\n",
    "    end = row.end\n",
    "    sent = doc[start].sent\n",
    "    targ = doc[start:end].text\n",
    "    if start == sent.start:\n",
    "        # empty left, target, full right pattern\n",
    "        tup = (\"\", targ, span_clean(doc[end : sent.end]))\n",
    "    elif end == sent.end:\n",
    "        tup = (span_clean(doc[sent.start : start]), targ, \"\")\n",
    "        # full left target empty right\n",
    "    else:\n",
    "        tup = (\n",
    "            span_clean(doc[sent.start : start]),\n",
    "            targ,\n",
    "            span_clean(doc[end : sent.end]),\n",
    "        )\n",
    "    result = {\n",
    "        \"ner_index\": row._name,\n",
    "        \"publication\": publication.name,\n",
    "        \"sentence\": sent,\n",
    "        \"Art_id\": row[\"Art_id\"],\n",
    "    }\n",
    "    # return result\n",
    "    result[\"Art_id\"] = row[\"Art_id\"]\n",
    "    result[\"debug\"] = \" \".join(tup)\n",
    "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "    try:\n",
    "        sentiment = tsc.infer_from_text(*tup)\n",
    "        # might need to add could not find target too.\n",
    "    except TooLongTextException as e:\n",
    "        logging.warning(\"TOO LONG?\", e)\n",
    "        result.update({label: None for label in labels})\n",
    "        return result\n",
    "    except TargetNotFoundException as e2:\n",
    "        logging.warning(\"TOO TARGET NOT FOUND?\", e2)\n",
    "        result.update({label: None for label in labels})\n",
    "        return result\n",
    "    result.update(\n",
    "        {\n",
    "            label: dct[\"class_prob\"]\n",
    "            for label in labels\n",
    "            for dct in sentiment\n",
    "            if dct[\"class_label\"] == label\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def getsent2(row, df_target, publication):\n",
    "    \"\"\"Basically wrapper around get_sentiment to set doc variable.\n",
    "    :param row: entity row.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = nlp(\n",
    "            df_target.loc[row.Art_id][\"Body\"],\n",
    "            disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"ner\"],\n",
    "        )\n",
    "        return get_sentiment(row, doc, publication)\n",
    "    except Exception as e:\n",
    "        logger.warning(e)\n",
    "        logging.warning(\n",
    "            \"exception encountered on article %s index %s\", row.Art_id, row._name\n",
    "        )\n",
    "        result = {\n",
    "            \"ner_index\": row._name,\n",
    "            \"publication\": publication.name,\n",
    "            \"sentence\": \"\",\n",
    "            \"Art_id\": row[\"Art_id\"],\n",
    "        }\n",
    "        labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "        result.update({label: None for label in labels})\n",
    "        return result\n",
    "\n",
    "\n",
    "def save(key, maindf, bucket=\"newyorktime\"):\n",
    "    # key = f\"{publication.name}/sentiment/{target}_test.csv\"\n",
    "    path = os.path.join( \"baba\", key)  # NOTE: baba in path. removed first arg utils.ROOTPATH,\n",
    "    logger.info(\"saving %s\", key)\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.makedirs(os.path.dirname(path))\n",
    "    maindf.to_csv(path)\n",
    "    logger.info(\"uploading to %s/%s\", bucket, key)\n",
    "    utils.upload_s3(path, bucket, key)\n",
    "\n",
    "\n",
    "# %%\n",
    "def run(pub, target, tts=\"full\", bucket=\"newyorktime\"):\n",
    "    \"\"\"Performs sentiment analysis on publications ner\n",
    "    :param sample: subsets data to just 10% train split.\n",
    "    :param tts: train test split: 'full', 'train', or 'test'.\n",
    "        train or test will filter for just that mask.\n",
    "    \"\"\"\n",
    "    # todo: get df from s3\n",
    "    nerdf = utils.standardize(\n",
    "        utils.read_df_s3(f\"{pub.name}/ner/ner_full.csv\", bucket),\n",
    "        # utils.get_df(pub, \"ner\", \"ner_full.csv\"),\n",
    "        pub,\n",
    "        drop_dups=False,\n",
    "    )\n",
    "    df = utils.standardize(\n",
    "        utils.read_df_s3(f\"{pub.name}/{pub.name}_full.csv\", bucket), pub\n",
    "    )\n",
    "    df = df.set_index(\"Art_id\")\n",
    "    if tts != \"full\":\n",
    "        split = utils.standardize(\n",
    "            utils.read_df_s3(f\"{pub.name}/tts_mask/{tts}_main1.csv\", bucket), pub\n",
    "        )\n",
    "        df = df[df.index.isin(split.Art_id)]\n",
    "        nerdf = nerdf[nerdf.Art_id.isin(split.Art_id)]\n",
    "\n",
    "    # filter maindf for only cases where baba shows up;\n",
    "    # takes 1.5 minutes to filter\n",
    "    mask = nerdf.entity.astype(str).str.lower().str.contains(target)\n",
    "    ner_target = nerdf[mask]\n",
    "    # scmp has 12627 entities to look up;\n",
    "    # ~1000 training examples\n",
    "    logger.info(f\"working on {len(ner_target)} entities\")\n",
    "    # masking main df takes 23 s\n",
    "    mask2 = df[\"Body\"].astype(str).str.lower().str.contains(target)\n",
    "    df_target = df[mask2]\n",
    "    logger.info(f\"working on {len(df_target)} documents\")\n",
    "    # 5007 documents with alibaba total; 432 in training set.\n",
    "    # 1.5-2s per iteration = 5 hours to run on full;30m-1 hr on subset\n",
    "    rows = ner_target.progress_apply(lambda row: getsent2(row, df_target, pub), axis=1)\n",
    "    maindf = pd.json_normalize(rows)\n",
    "    key = f\"{pub.name}/sentiment/{target}_{tts}.csv\"\n",
    "    save(key, maindf, bucket)\n",
    "    return maindf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92278e69-aa3a-4065-83ff-c504175ddf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "target = \"alibaba\"\n",
    "bucket = \"aliba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75408392-79a6-4e16-b180-66726ef07a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 16:14:53,892 [INFO] __main__: working on 166 entities\n",
      "2022-07-08 16:14:53,904 [INFO] __main__: working on 87 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/166 [00:00<?, ?it/s]/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 46%|████▌     | 76/166 [01:26<01:44,  1.16s/it]--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_22887/2493925981.py\", line 77, in get_sentiment\n",
      "    sentiment = tsc.infer_from_text(*tup)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/infer.py\", line 84, in infer_from_text\n",
      "    return self.infer(text_left=left, target_mention=target, text_right=right)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/infer.py\", line 131, in infer\n",
      "    indexed_example = self.tokenizer.create_model_input_seqs(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/dataset.py\", line 753, in create_model_input_seqs\n",
      "    target_mask_seq_for_text_with_special_tokens = self._create_target_mask(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/dataset.py\", line 442, in _create_target_mask\n",
      "    raise TooLongTextException()\n",
      "NewsSentiment.customexceptions.TooLongTextException\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 929, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 668, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 373, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/__main__.py\", line 4, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_22887/3063809932.py\", line 3, in <cell line: 3>\n",
      "    maindf = utils.timeit(run, pub, target, \"train\", bucket)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/thesisutils/utils.py\", line 112, in timeit\n",
      "    ret = fn(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_22887/2493925981.py\", line 174, in run\n",
      "    rows = ner_target.progress_apply(lambda row: getsent2(row, df_target, pub), axis=1)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/tqdm/std.py\", line 814, in inner\n",
      "    return getattr(df, df_function)(wrapper, **kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/frame.py\", line 8845, in apply\n",
      "    return op.apply().__finalize__(self, method=\"apply\")\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/apply.py\", line 733, in apply\n",
      "    return self.apply_standard()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/apply.py\", line 857, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/apply.py\", line 873, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/tqdm/std.py\", line 809, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_22887/2493925981.py\", line 174, in <lambda>\n",
      "    rows = ner_target.progress_apply(lambda row: getsent2(row, df_target, pub), axis=1)\n",
      "  File \"/tmp/ipykernel_22887/2493925981.py\", line 108, in getsent2\n",
      "    return get_sentiment(row, doc, publication)\n",
      "  File \"/tmp/ipykernel_22887/2493925981.py\", line 80, in get_sentiment\n",
      "    logging.warning(\"TOO LONG?\", e)\n",
      "Message: 'TOO LONG?'\n",
      "Arguments: (TooLongTextException(),)\n",
      "100%|██████████| 166/166 [03:06<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 16:18:00,311 [INFO] __main__: saving hkfp/sentiment/alibaba_train.csv\n",
      "2022-07-08 16:18:00,332 [INFO] __main__: uploading to aliba/hkfp/sentiment/alibaba_train.csv\n",
      "run took 186.85149712199996 secs\n",
      "   ner_index publication                                           sentence  \\\n",
      "0         29        hkfp  (\\n, The, 51, -, year, -, old, founder, of, in...   \n",
      "1         49        hkfp  (His, Alibaba, went, public, at, the, New, Yor...   \n",
      "2        118        hkfp  (\\n, Taobao, ’s, parent, company, Alibaba, Gro...   \n",
      "3        120        hkfp  (\\n, In, a, statement, to, Hong, Kong, Free, P...   \n",
      "4        220        hkfp  (\\n, However, ,, unlike, Black, Friday, ,, Chi...   \n",
      "\n",
      "        Art_id                                              debug  negative  \\\n",
      "0   post-18508  \\nThe 51-year-old founder of internet giant Al...  0.083025   \n",
      "1   post-18508  His Alibaba went public at the New York Stock ...  0.025798   \n",
      "2   post-28348  \\nTaobao’s parent company Alibaba Group said l...  0.205926   \n",
      "3   post-28348  \\nIn a statement to Hong Kong Free Press, a sp...  0.058455   \n",
      "4  post-139765  \\nHowever, unlike Black Friday, China’s Novemb...  0.301517   \n",
      "\n",
      "    neutral  positive  \n",
      "0  0.458300  0.458676  \n",
      "1  0.137827  0.836376  \n",
      "2  0.761290  0.032784  \n",
      "3  0.630074  0.311471  \n",
      "4  0.392628  0.305856  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "pub = utils.publications[\"hkfp\"]\n",
    "maindf = utils.timeit(run, pub, target, \"train\", bucket)\n",
    "print(maindf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed89b12d-f6c5-43bf-b2be-8df11bb534de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 16:51:42,065 [INFO] __main__: working on 193 entities\n",
      "2022-07-08 16:51:42,086 [INFO] __main__: working on 87 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/193 [00:00<?, ?it/s]/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 77%|███████▋  | 149/193 [02:33<00:46,  1.06s/it]--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_22887/2493925981.py\", line 77, in get_sentiment\n",
      "    sentiment = tsc.infer_from_text(*tup)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/infer.py\", line 84, in infer_from_text\n",
      "    return self.infer(text_left=left, target_mention=target, text_right=right)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/infer.py\", line 131, in infer\n",
      "    indexed_example = self.tokenizer.create_model_input_seqs(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/dataset.py\", line 815, in create_model_input_seqs\n",
      "    text_dependency_tree_hop_distances = self._create_dependency_tree_hop_distances_of_tokens_to_target(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/dataset.py\", line 650, in _create_dependency_tree_hop_distances_of_tokens_to_target\n",
      "    dist = self._calculate_dep_distance(text_tokens, text_left_len, target_phrase)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/dataset.py\", line 327, in _calculate_dep_distance\n",
      "    raise TargetNotFoundException(\n",
      "NewsSentiment.customexceptions.TargetNotFoundException: no target found: [ALSO, ON, HKFP, Hong, Kong, election, pledge, of, ‘, no, change, ’, among, candidate, introductions, ,, only, 4, of, 153, mention, democracy, Despite, the, apparent, purge, of, Hong, Kong, universities, ,, changing, people, ’s, minds, is, harder, than, it, looks, Hong, Kong, to, deploy, over, 10,000, police, to, ensure, ‘, patriots, -, only, ’, legislative, polls, run, smoothly, Disney+, appears, to, censor, episode, of, The, Simpsons, in, Hong, Kong, referencing, Tiananmen, Massacre, Jack, Ma, ,, founder, of, Chinese, e, -, commerce, conglomerate, Alibaba, and, Asia, ’s, richest, man, ,, met, with, President, of, the, United, States, Barack, Obama, during, a, secretive, lunch, at, the, White, House, on, Tuesday], 466, Alibaba\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 929, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 668, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 373, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/__main__.py\", line 4, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_22887/1819899190.py\", line 2, in <cell line: 2>\n",
      "    maindf = utils.timeit(run, pub, target, \"test\", bucket)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/thesisutils/utils.py\", line 112, in timeit\n",
      "    ret = fn(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_22887/2493925981.py\", line 174, in run\n",
      "    rows = ner_target.progress_apply(lambda row: getsent2(row, df_target, pub), axis=1)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/tqdm/std.py\", line 814, in inner\n",
      "    return getattr(df, df_function)(wrapper, **kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/frame.py\", line 8845, in apply\n",
      "    return op.apply().__finalize__(self, method=\"apply\")\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/apply.py\", line 733, in apply\n",
      "    return self.apply_standard()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/apply.py\", line 857, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/apply.py\", line 873, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/tqdm/std.py\", line 809, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_22887/2493925981.py\", line 174, in <lambda>\n",
      "    rows = ner_target.progress_apply(lambda row: getsent2(row, df_target, pub), axis=1)\n",
      "  File \"/tmp/ipykernel_22887/2493925981.py\", line 108, in getsent2\n",
      "    return get_sentiment(row, doc, publication)\n",
      "  File \"/tmp/ipykernel_22887/2493925981.py\", line 84, in get_sentiment\n",
      "    logging.warning(\"TOO TARGET NOT FOUND?\", e2)\n",
      "Message: 'TOO TARGET NOT FOUND?'\n",
      "Arguments: (TargetNotFoundException('no target found: [ALSO, ON, HKFP, Hong, Kong, election, pledge, of, ‘, no, change, ’, among, candidate, introductions, ,, only, 4, of, 153, mention, democracy, Despite, the, apparent, purge, of, Hong, Kong, universities, ,, changing, people, ’s, minds, is, harder, than, it, looks, Hong, Kong, to, deploy, over, 10,000, police, to, ensure, ‘, patriots, -, only, ’, legislative, polls, run, smoothly, Disney+, appears, to, censor, episode, of, The, Simpsons, in, Hong, Kong, referencing, Tiananmen, Massacre, Jack, Ma, ,, founder, of, Chinese, e, -, commerce, conglomerate, Alibaba, and, Asia, ’s, richest, man, ,, met, with, President, of, the, United, States, Barack, Obama, during, a, secretive, lunch, at, the, White, House, on, Tuesday], 466, Alibaba'),)\n",
      "100%|██████████| 193/193 [03:20<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 16:55:02,351 [INFO] __main__: saving hkfp/sentiment/alibaba_test.csv\n",
      "2022-07-08 16:55:02,371 [INFO] __main__: uploading to aliba/hkfp/sentiment/alibaba_test.csv\n",
      "run took 200.75716947699993 secs\n",
      "   ner_index publication                                           sentence  \\\n",
      "0         14        hkfp  (\\n, According, to, Sina, News, ,, internet, c...   \n",
      "1         72        hkfp  (\\n, Other, large, retailers, including, eBay,...   \n",
      "2         86        hkfp  (\\n, In, China, ,, where, Alibaba, lends, to, ...   \n",
      "3        128        hkfp  (\\n, Ma, ,, Alibaba, ’s, founder, ,, bought, t...   \n",
      "4        158        hkfp  (\\n, Update, (, 14:00, August, 17, ):, A, spok...   \n",
      "\n",
      "       Art_id                                              debug  negative  \\\n",
      "0  post-16926  \\nAccording to Sina News, internet companies i...  0.041235   \n",
      "1  post-17316  \\nOther large retailers including eBay Inc’s P...  0.035805   \n",
      "2  post-17316  \\nIn China, where Alibaba lends to small busin...  0.067813   \n",
      "3  post-26827  \\nMa, Alibaba ’s founder, bought the house fro...  0.028935   \n",
      "4  post-26827  \\nUpdate(14:00 August 17): A spokesperson for ...  0.168052   \n",
      "\n",
      "    neutral  positive  \n",
      "0  0.864819  0.093946  \n",
      "1  0.166046  0.798149  \n",
      "2  0.220979  0.711209  \n",
      "3  0.787141  0.183924  \n",
      "4  0.819469  0.012479  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pub = utils.publications[\"hkfp\"]\n",
    "maindf = utils.timeit(run, pub, target, \"test\", bucket)\n",
    "print(maindf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2973081-783c-4efb-b777-f9ed71841a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 16:46:36,230 [INFO] __main__: working on 295 entities\n",
      "2022-07-08 16:46:36,240 [INFO] __main__: working on 166 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/295 [00:00<?, ?it/s]/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 295/295 [04:52<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 16:51:28,836 [INFO] __main__: saving nyt/sentiment/alibaba_train.csv\n",
      "2022-07-08 16:51:28,860 [INFO] __main__: uploading to aliba/nyt/sentiment/alibaba_train.csv\n",
      "run took 293.08249660799993 secs\n",
      "   ner_index publication                                           sentence  \\\n",
      "0         14         nyt  (Alibaba.com, ,, a, fast, -, growing, Chinese,...   \n",
      "1         17         nyt  (\\n\\n, In, a, statement, released, late, Monda...   \n",
      "2         22         nyt  (But, the, announcement, stunned, the, technol...   \n",
      "3         56         nyt  (The, company, has, been, in, negotiations, wi...   \n",
      "4         84         nyt  (She, recently, closed, a, $, 7.6, billion, de...   \n",
      "\n",
      "                                              Art_id  \\\n",
      "0  https://www.nytimes.com/2011/02/22/business/gl...   \n",
      "1  https://www.nytimes.com/2011/02/22/business/gl...   \n",
      "2  https://www.nytimes.com/2011/02/22/business/gl...   \n",
      "3  https://www.nytimes.com/2012/01/18/technology/...   \n",
      "4  https://www.nytimes.com/2012/09/26/technology/...   \n",
      "\n",
      "                                               debug  negative   neutral  \\\n",
      "0   Alibaba.com , a fast-growing Chinese electron...  0.497272  0.444448   \n",
      "1  \\n\\nIn a statement released late Monday, Aliba...  0.105850  0.872313   \n",
      "2  But the announcement stunned the technology co...  0.079856  0.162843   \n",
      "3  The company has been in negotiations with Alib...  0.036699  0.853110   \n",
      "4  She recently closed a $7.6 billion deal with A...  0.236594  0.662058   \n",
      "\n",
      "   positive  \n",
      "0  0.058280  \n",
      "1  0.021838  \n",
      "2  0.757301  \n",
      "3  0.110192  \n",
      "4  0.101349  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pub = utils.publications[\"nyt\"]\n",
    "maindf = utils.timeit(run, pub, target, \"train\", bucket)\n",
    "print(maindf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84470e51-3a9b-403c-b1ff-d655f9015308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 16:55:02,873 [INFO] __main__: working on 313 entities\n",
      "2022-07-08 16:55:02,881 [INFO] __main__: working on 171 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 313/313 [05:14<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 17:00:16,972 [INFO] __main__: saving nyt/sentiment/alibaba_test.csv\n",
      "2022-07-08 17:00:16,994 [INFO] __main__: uploading to aliba/nyt/sentiment/alibaba_test.csv\n",
      "run took 314.56090909700015 secs\n",
      "   ner_index publication                                           sentence  \\\n",
      "0          2         nyt  (\\n\\n, But, just, as, quickly, as, it, began, ...   \n",
      "1          6         nyt  (\\n\\n, The, announcement, is, a, bid, to, end,...   \n",
      "2          9         nyt  (\\n\\n, The, announcement, is, a, bid, to, end,...   \n",
      "3         13         nyt  (\\n\\n, Shares, of, Yahoo, plunged, after, the,...   \n",
      "4         76         nyt  (\\n\\n, Largely, because, of, a, long, -, await...   \n",
      "\n",
      "                                              Art_id  \\\n",
      "0  https://www.nytimes.com/2011/05/16/technology/...   \n",
      "1  https://www.nytimes.com/2011/05/16/technology/...   \n",
      "2  https://www.nytimes.com/2011/05/16/technology/...   \n",
      "3  https://www.nytimes.com/2011/05/16/technology/...   \n",
      "4  https://www.nytimes.com/2012/10/23/technology/...   \n",
      "\n",
      "                                               debug  negative   neutral  \\\n",
      "0  \\n\\nBut just as quickly as it began, Yahoo and...  0.049404  0.397603   \n",
      "1  \\n\\nThe announcement is a bid to end a feud th...  0.840045  0.135416   \n",
      "2  \\n\\nThe announcement is a bid to end a feud th...  0.837104  0.138689   \n",
      "3  \\n\\nShares of Yahoo plunged after the statemen...  0.409649  0.509369   \n",
      "4  \\n\\nLargely because of a long-awaited sale of ...  0.123057  0.594045   \n",
      "\n",
      "   positive  \n",
      "0  0.552993  \n",
      "1  0.024539  \n",
      "2  0.024207  \n",
      "3  0.080981  \n",
      "4  0.282899  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pub = utils.publications[\"nyt\"]\n",
    "maindf = utils.timeit(run, pub, target, \"test\", bucket)\n",
    "print(maindf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31881c9-d68d-47ca-9b40-b11f6f091697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub = utils.publications[\"globaltimes\"]\n",
    "# maindf = utils.timeit(run, pub, target, \"train\", bucket)\n",
    "# print(maindf.head())\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7fcc07-ad0f-42c0-a2c5-4d12c09d4ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 18:52:51,309 [INFO] __main__: working on 5903 entities\n",
      "2022-07-08 18:52:51,332 [INFO] __main__: working on 2344 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5903 [00:00<?, ?it/s]/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 69%|██████▉   | 4077/5903 [1:06:42<29:28,  1.03it/s]--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2295/2493925981.py\", line 77, in get_sentiment\n",
      "    sentiment = tsc.infer_from_text(*tup)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/infer.py\", line 84, in infer_from_text\n",
      "    return self.infer(text_left=left, target_mention=target, text_right=right)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/infer.py\", line 131, in infer\n",
      "    indexed_example = self.tokenizer.create_model_input_seqs(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/dataset.py\", line 753, in create_model_input_seqs\n",
      "    target_mask_seq_for_text_with_special_tokens = self._create_target_mask(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/NewsSentiment/dataset.py\", line 442, in _create_target_mask\n",
      "    raise TooLongTextException()\n",
      "NewsSentiment.customexceptions.TooLongTextException\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 929, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 668, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/logging/__init__.py\", line 373, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/__main__.py\", line 4, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2295/317643103.py\", line 2, in <cell line: 2>\n",
      "    maindf = utils.timeit(run, pub, target, \"test\", bucket)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/thesisutils/utils.py\", line 112, in timeit\n",
      "    ret = fn(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_2295/2493925981.py\", line 174, in run\n",
      "    rows = ner_target.progress_apply(lambda row: getsent2(row, df_target, pub), axis=1)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/tqdm/std.py\", line 814, in inner\n",
      "    return getattr(df, df_function)(wrapper, **kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/frame.py\", line 8845, in apply\n",
      "    return op.apply().__finalize__(self, method=\"apply\")\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/apply.py\", line 733, in apply\n",
      "    return self.apply_standard()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/apply.py\", line 857, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/pandas/core/apply.py\", line 873, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/tqdm/std.py\", line 809, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_2295/2493925981.py\", line 174, in <lambda>\n",
      "    rows = ner_target.progress_apply(lambda row: getsent2(row, df_target, pub), axis=1)\n",
      "  File \"/tmp/ipykernel_2295/2493925981.py\", line 108, in getsent2\n",
      "    return get_sentiment(row, doc, publication)\n",
      "  File \"/tmp/ipykernel_2295/2493925981.py\", line 80, in get_sentiment\n",
      "    logging.warning(\"TOO LONG?\", e)\n",
      "Message: 'TOO LONG?'\n",
      "Arguments: (TooLongTextException(),)\n",
      " 81%|████████▏ | 4798/5903 [1:18:32<18:10,  1.01it/s]"
     ]
    }
   ],
   "source": [
    "pub = utils.publications[\"globaltimes\"]\n",
    "maindf = utils.timeit(run, pub, target, \"test\", bucket)\n",
    "print(maindf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc616f-c3fb-41ec-8f29-b70e1266d474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 20:46:06,196 [INFO] __main__: working on 9608 entities\n",
      "2022-07-08 20:46:06,240 [INFO] __main__: working on 3609 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9608 [00:00<?, ?it/s]/home/ec2-user/SageMaker/.persisted_conda/newssent/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 3699/9608 [1:00:46<1:35:40,  1.03it/s]"
     ]
    }
   ],
   "source": [
    "pub = utils.publications[\"chinadaily\"]\n",
    "maindf = utils.timeit(run, pub, target, \"train\", bucket)\n",
    "print(maindf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab8e556-f875-4429-bbd8-5d99ea078de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = utils.publications[\"scmp\"]\n",
    "maindf = utils.timeit(run, pub, target, \"test\", bucket)\n",
    "print(maindf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f35ae-22f7-447a-806d-7221efc7c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# %%\n",
    "pub = utils.publications[\"globaltimes\"]\n",
    "maindf = utils.timeit(run, pub, target, \"train\", bucket)\n",
    "print(maindf.head())\n",
    "# %%\n",
    "pub = utils.publications[\"scmp\"]\n",
    "maindf = utils.timeit(run, pub, target, \"train\", bucket)\n",
    "print(maindf.head())\n",
    "# %%\n",
    "\n",
    "# sanity check the post removal works.\n",
    "# y = maindf.sentence.str.contains(\"Post\")\n",
    "# y.apply(lambda d: print(d.debug, \"\\n\", d.sentence, \"\\n new \\n\"), axis=1)\n",
    "\n",
    "# %%\n",
    "# GROUP APPROACH SLIGHTLY SLOWER? ########################################\n",
    "# groups = ner_target.groupby(\"Art_id\")\n",
    "# dfls = []\n",
    "# groups = ner_target.groupby(\"Art_id\")\n",
    "# for name, group in tqdm(list(groups)):\n",
    "#     # if name == 876073:\n",
    "#         print(name)\n",
    "#         doc = nlp(\n",
    "#             df_target.loc[name][\"Body\"],\n",
    "#             disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"ner\"],\n",
    "#         )\n",
    "# mask = group.entity.str.lower().str.contains(\"alibaba\")\n",
    "# filtered = group[mask]\n",
    "# if len(filtered) > 0:\n",
    "# res = group.progress_apply(lambda row: get_sentiment(row, doc, pub), axis=1)\n",
    "# resdf = pd.json_normalize(res)\n",
    "# dfls.append(resdf)\n",
    "# maindf = pd.concat(dfls)\n",
    "# len(list(groups))\n",
    "# %%\n",
    "# name\n",
    "# group\n",
    "# dfls = []\n",
    "\n",
    "# ner_baba\n",
    "# ner_target.Art_id.eq(876073).value_counts()\n",
    "# for name, group in list(groups)[:5]:\n",
    "#     doc = nlp(\n",
    "#         df_target.loc[name][\"Body\"],\n",
    "#         disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"ner\"],\n",
    "#     )\n",
    "#     # mask = group.entity.str.lower().str.contains(\"alibaba\")\n",
    "#     # filtered = group[mask]\n",
    "#     # if len(filtered) > 0:\n",
    "#     res = group.apply(lambda row: get_sentiment(row, doc), axis=1)\n",
    "#     resdf = pd.json_normalize(res)\n",
    "#     dfls.append(resdf)\n",
    "# # takes 30 seconds to run on 5 groups which is 18 entities\n",
    "\n",
    "# very slow for now...\n",
    "# but does get sentiment for each relevant entity;\n",
    "# seems better to filter for baba before grouping bc group operations suck.\n",
    "# maindf = pd.concat(dfls)\n",
    "# maindf\n",
    "# upload to s3 here.\n",
    "\n",
    "# %%\n",
    "\n",
    "# import logging\n",
    "\n",
    "# import pandas as pd\n",
    "# import neuralcoref\n",
    "# %%\n",
    "# COREFF APPORACH OLD######################################\n",
    "# import spacy\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# nlp = spacy.load(\"en_core_web_md\")\n",
    "# neuralcoref.add_to_pipe(nlp)\n",
    "# #%%\n",
    "# doc = nlp(\"My sister has a dog. She loves him.\")\n",
    "# nlp.remove_pipe(name=\"neuralcoref\")\n",
    "# coref = neuralcoref.NeuralCoref(\n",
    "#     nlp.vocab, conv_dict={\"Lam\": [\"woman\", \"Carrie\", \"executive\"]}\n",
    "# )\n",
    "# nlp.add_pipe(coref, name=\"neuralcoref\")\n",
    "# doc = nlp(\n",
    "#     \"Carrie Lam passed the extradition bill, which Ted Hui said will ruin Hong Kong. Lam disagrees with him.\"\n",
    "# )\n",
    "# doc._.has_coref\n",
    "# doc._.coref_clusters[1].main.text  # .mentions[0].text\n",
    "# doc._.coref_scores\n",
    "# doc._.coref_resolved\n",
    "\n",
    "# #%%\n",
    "# df = pd.read_csv(r\"C:\\Users\\tlebr\\OneDrive - pku.edu.cn\\Thesis\\data\\scmp\\2021.csv\")\n",
    "# row = df.iloc[3]\n",
    "# r\n",
    "# doc = nlp(row.Body)\n",
    "\n",
    "# ppl = [ent for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "# ppl[-1].start\n",
    "# ppl[-1].end\n",
    "# sent_start = ppl[-1].sent.start\n",
    "# off_start = ppl[-1].start - sent_start\n",
    "# off_end = ppl[-1].end\n",
    "# ppl[-1].sent\n",
    "# [p.sent for p in ppl][-1].start\n",
    "# [0]\n",
    "# # .start\n",
    "# # [1]\n",
    "\n",
    "# doc.ents[0].label_ == \"PERSON\"\n",
    "# print(x.Body)\n",
    "maindf.tail()[[\"negative\", \"positive\", \"neutral\"]]\n",
    "maindf.tail().debug.apply(print)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_newssent",
   "language": "python",
   "name": "conda_newssent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
