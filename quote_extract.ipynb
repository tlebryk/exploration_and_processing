{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139dafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import spacy\n",
    "from quotes import quote_extractor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cb5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d122319",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "def read_df_s3(object_key, bucket=\"newyorktime\"):\n",
    "    \"\"\"Reads a csv from s3 and loads into pandas;\n",
    "    Means do not have to store large files locally anymore. \n",
    "    \"\"\"\n",
    "    csv_obj = s3.get_object(Bucket=bucket, Key=object_key)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_string))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8785980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2011\n",
    "paper = \"scmp\"\n",
    "bucket = \"newyorktime\"\n",
    "key = f\"{paper}/{year}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a950a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "639ea012",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ccfb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join('data', key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "146596e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname(filepath) and os.makedirs(os.path.dirname(filepath), exist_ok=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "127aadcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(bucket, key, filepath)\n",
    "\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a8c1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(fn, *args, **kwargs):\n",
    "    s = time.perf_counter()\n",
    "    ret = fn(*args, **kwargs)\n",
    "    e = time.perf_counter()\n",
    "    print(f\"{fn.__name__} took {e-s} secs\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0deda840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quotes(row, text_col, uid_col, publication=\"scmp\", year=\"2012\"):\n",
    "    \"\"\"Row is a row in a dataframe with a text column and unique idenifier column.\"\"\"\n",
    "    doc = nlp(row[text_col], disable=[\n",
    "        \"tagger\",\n",
    "        \"attribute_ruler\",\n",
    "        \"lemmatizer\"\n",
    "    ])\n",
    "    # list of dictionaries\n",
    "    final_quotes = quote_extractor.extract_quotes(row[uid_col], doc)\n",
    "    for item in final_quotes:\n",
    "        item[\"source\"] = row[uid_col]\n",
    "        item[\"publication\"] = publication\n",
    "        item[\"year\"] = year\n",
    "    return final_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6634c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(input_df, output_name, publication=\"scmp\", year=\"2012\"):\n",
    "    quote_dcts = input_df.apply(\n",
    "        lambda row: extract_quotes(row, \"Body\", \"Index\", publication, year), axis=1\n",
    "    )\n",
    "    quotedf = pd.json_normalize(quote_dcts.explode()).dropna().convert_dtypes()\n",
    "    quotedf.to_csv(output_name)\n",
    "    return quotedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bebcf217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_s3(filepath, bucket, key=None):\n",
    "    if not key:\n",
    "        key = filepath\n",
    "    try:\n",
    "        response = s3_client.upload_file(filepath, bucket, key)\n",
    "        return response\n",
    "    except ClientError as e:\n",
    "        logging.exception(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e9d684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quotedf = timeit(run, df, path)\n",
    "# upload_s3(path, bucket, key=f\"{paper}/quotes/q_{year}.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e777e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad508fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on  scmp/2019.csv\n",
      "run took 3885.209267205 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [1:04:50<1:04:50, 3890.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on  scmp/2020.csv\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm(range(2019, 2021)):\n",
    "    key = f\"{paper}/{year}.csv\"\n",
    "    filepath = os.path.join('data', key)    \n",
    "    path = f\"quotes_{paper}_{year}.csv\"\n",
    "    print(\"working on \", key)\n",
    "    s3_client.download_file(bucket, key, filepath)\n",
    "    df = pd.read_csv(filepath)\n",
    "    df[\"Body\"] = df.Body.astype(str)\n",
    "    quotedf = timeit(run, df, path, paper, year)\n",
    "    upload_s3(path, bucket, key=f\"{paper}/quotes/q_{year}.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa092fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_nlp",
   "language": "python",
   "name": "conda_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
